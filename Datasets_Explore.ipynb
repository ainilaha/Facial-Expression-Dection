{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Introduction\n",
    "\n",
    "This notebook is highly depend on **P. Lucey, J. F. Cohn, T. Kanade, J. Saragih, Z. Ambadar and I. Matthews, \"The Extended Cohn-Kanade Dataset (CK+): A complete dataset for action unit and emotion-specified expression,\" 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Workshops, San Francisco, CA, 2010, pp. 94-101.**\n",
    "\n",
    "### 1.1 CK vs CK+\n",
    "The [Cohn-Kanade AU-Coded Facial Expression Database](https://www.pitt.edu/~emotion/ck-spread.htm) is for research in automatic facial image analysis and synthesis and for perceptual studies. Cohn-Kanade is available in two versions and a third is in preparation.\n",
    "\n",
    "- The CK (or DFAT) database contains 486 sequences across 97 subjects.\n",
    "- Extended Cohn-Kanade (CK+) database added another 107 sequences as well as another 26 subjects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 The Extended Cohn-Kanade (CK+) Dataset\n",
    "\n",
    "Facial behavior of 210 adults was recorded using two hardware synchronized Panasonic AG-7500 cameras. Participants were 18 to 50 years of age, 69% female, 81%, Euro-American, 13% Afro-American, and 6% other groups. Participants were instructed by an experimenter to perform a series of 23 facial displays; these included single action units and combinations of action units.Each display began and ended in a neutral face with any exceptions noted. Im- age sequences for frontal views and 30-degree views were digitized into either 640x490 or 640x480 pixel arrays with 8- bit gray-scale or 24-bit color values\n",
    "\n",
    "For the CK+ distribution, we have augmented the dataset further to include 593 se- quences from 123 subjects (an additional 107 (22%) se- quences and 26 (27%) subjects). The image **sequence vary in duration (i.e. 10 to 60 frames)** and incorporate the onset (which is also the neutral frame) to peak formation of the facial expressions\n",
    "![examples](images/examples.jpg)\n",
    "\n",
    "All image data from the pool of **593 sequences** that had a nominal emotion label based on the subjectâ€™s impression of each of the **7 basic emotion categories: Anger,Contempt, Disgust, Fear, Happy, Sadness and Surprise.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Exploratory "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Landmaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os\n",
    "def getListOfFiles(dirName):\n",
    "    # create a list of file and sub directories \n",
    "    # names in the given directory \n",
    "    listOfFile = os.listdir(dirName)\n",
    "    allFiles = list()\n",
    "    files_label = {}\n",
    "    # Iterate over all the entries\n",
    "    for entry in listOfFile:\n",
    "        # Create full path\n",
    "        fullPath = os.path.join(dirName, entry)\n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles = allFiles + getListOfFiles(fullPath)[0]\n",
    "        else:\n",
    "            fo = open(fullPath, \"r+\")\n",
    "            label = fo.readlines()\n",
    "            label = label[0].strip()\n",
    "#             print(entry,\":\",label);\n",
    "            fo.close()\n",
    "            allFiles.append(entry)\n",
    "            files_label[entry.replace(\".txt\",'')] = label\n",
    "            \n",
    "                \n",
    "    return allFiles,files_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def read_files_label(path):\n",
    "    files_label = pd.DataFrame(columns=['files','label'])\n",
    "    for sub_path in os.listdir(path):\n",
    "        sub_path = os.path.join(path,sub_path)\n",
    "        for ssub in os.listdir(sub_path):\n",
    "            file_path = os.path.join(sub_path,ssub)\n",
    "            for file in os.listdir(file_path):\n",
    "                fo = open(os.path.join(file_path,file), \"r+\")\n",
    "                label = fo.readlines()\n",
    "                label = label[0].strip()\n",
    "                fo.close()\n",
    "                files_label = files_label.append({\"files\":file.replace(\".txt\",''), \"label\":label.replace(\".0000000e+00\",\"\")}, ignore_index=True)\n",
    "    return files_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"D:/Projects/CK_plus/datasets/Emotion\"\n",
    "files_label = read_files_label(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>files</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S005_001_00000011_emotion</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S010_002_00000014_emotion</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S010_004_00000019_emotion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S010_006_00000015_emotion</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S011_001_00000016_emotion</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       files label\n",
       "0  S005_001_00000011_emotion     3\n",
       "1  S010_002_00000014_emotion     7\n",
       "2  S010_004_00000019_emotion     1\n",
       "3  S010_006_00000015_emotion     5\n",
       "4  S011_001_00000016_emotion     7"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2  FACS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Emotional Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Base Line Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Active Appearance Model (AAM) \n",
    "### 3.2  Support Vector Machines (SVMs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
